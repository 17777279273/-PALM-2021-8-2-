{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨常规赛：PALM眼底彩照视盘探测与分割\n",
    "### [比赛传送门](https://aistudio.baidu.com/aistudio/competition/detail/87)\n",
    "\n",
    "常规赛简介\n",
    "\n",
    "飞桨（PaddlePaddle）以百度多年的深度学习技术研究和业务应用为基础，是中国首个开源开放、技术领先、功能完备的产业级深度学习平台。更多飞桨资讯，点击此处查看。\n",
    "\n",
    "飞桨常规赛由百度飞桨于 2019 年发起，面向全球 AI 开发者，赛题范围广，涵盖领域多。常规赛旨在通过长期发布的经典比赛项目，为开发者提供学习锻炼机会，助力大家在飞桨大赛中获得骄人成绩。\n",
    "\n",
    "参赛选手需使用飞桨框架，基于特定赛题下的真实行业数据完成并提交任务。常规赛采取月度评比方式，为打破历史最高记录选手和当月有资格参与月度评奖的前 10 名选手提供飞桨特别礼包奖励。更多惊喜，更多收获，尽在飞桨常规赛。\n",
    "\n",
    "赛题介绍\n",
    "本赛题原型为ISBI2019PALM眼科大赛。 近视已成为全球公共卫生负担。在近视患者中，约35%为高度近视。近视导致眼轴长度的延长，可能引起视网膜和脉络膜的病理改变。随着近视屈光度的增加，高度近视将发展为病理性近视，其特点是病理改变的形成:(1)后极，包括镶嵌型眼底、后葡萄肿、视网膜脉络膜变性等;(2)视盘，包括乳头旁萎缩、倾斜等;(3)近视性黄斑，包括漆裂、福氏斑、CNV等。病理性近视对患者造成不可逆的视力损害。因此，早期诊断和定期随访非常重要。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/27fabb47f8af452087086140c147338180bcea215bee48c1b5c7f6e270c8ff2d)\n",
    "\n",
    "视网膜由黄斑向鼻侧约3mm处有一直径约1.5mm、境界清楚的淡红色圆盘状结构，称为视神经盘，简称视盘。视盘是眼底图像的一个重要特征，对其进行准确、快速地定位与分割对利用眼底图像进行疾病辅助诊断具有重要意义。\n",
    " ### 比赛任务\n",
    "该任务目的是对眼底图像的视盘进行检测，若存在视盘结构，需从眼底图像中分割出视盘区域；若无视盘结构，分割结果直接置全背景。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c584ee43a27947b6b8908464fa1d90386490eca0ddcd43ae86d9e5251e569071)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据集介绍\n",
    "本次常规赛提供的金标准由中山大学中山眼科中心的7名眼科医生手工进行视盘像素级标注，之后由另一位高级专家将它们融合为最终的标注结果。存储为BMP图像，与对应的眼底图像大小相同，标签为0代表视盘（黑色区域）；标签为255代表其他（白色区域）。\n",
    "\n",
    "训练数据集\n",
    "\n",
    "文件名称：Train\n",
    "Train文件夹里有fundus_images文件夹和Disc_Masks文件夹。\n",
    "\n",
    "fundus_images文件夹内包含800张眼底彩照，分辨率为1444×1444，或2124×2056。命名形如H0001.jpg、N0001.jpg、P0001.jpg和V0001.jpg。\n",
    "\n",
    "Disc_Masks文件夹内包含fundus_images里眼底彩照的视盘分割金标准，大小与对应的眼底彩照一致。命名前缀和对应的fundus_images文件夹里的图像命名一致，后缀为bmp。\n",
    "\n",
    "测试数据集\n",
    "\n",
    "文件名称：PALM-Testing400-Images\n",
    "\n",
    "包含400张眼底彩照，命名形如T0001.jpg。\n",
    "\n",
    "数据集下载：\n",
    "\n",
    "[常规赛：PALM眼底彩照视盘探测与分割数据集](https://bj.bcebos.com/v1/dataset-bj/%E5%8C%BB%E7%96%97%E6%AF%94%E8%B5%9B/%E5%B8%B8%E8%A7%84%E8%B5%9B%EF%BC%9APALM%E7%9C%BC%E5%BA%95%E5%BD%A9%E7%85%A7%E8%A7%86%E7%9B%98%E6%8E%A2%E6%B5%8B%E4%B8%8E%E5%88%86%E5%89%B2.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 比赛思路\n",
    "看到语义分割就应该想到`PaddleSeg`套件啦！可对照[PaddleSeg代码解读项目](https://aistudio.baidu.com/aistudio/projectdetail/1136799)搭建自己的项目\n",
    "\n",
    "\n",
    "> 先用Unet进行分割。对预测结果进行处理。\n",
    "\n",
    "> 进行分割结果孔洞填充\n",
    "\n",
    "> 假如某一张图片预测的结果出现多个不连通的区域，通过面积筛选，只保留最大的面积。（可提升一点dice）\n",
    "\n",
    "`PLAM_model_4`成绩为：0.94979"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一、数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.11、解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#解压数据\r\n",
    "!unzip -o data/data86770/seg.zip -d /home/aistudio/work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.2、划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\r\n",
    "import os\r\n",
    "random.seed(2021)\r\n",
    "mask_dir  = '/home/aistudio/work/seg/Train/masks'\r\n",
    "img_dir = '/home/aistudio/work/seg/Train/fundus_image'\r\n",
    "path_list = list()\r\n",
    "for img in os.listdir(img_dir):\r\n",
    "    img_path = os.path.join(img_dir,img)\r\n",
    "    mask_path = os.path.join(mask_dir,img.replace('jpg', 'png'))\r\n",
    "    path_list.append((img_path, mask_path))\r\n",
    "random.shuffle(path_list)\r\n",
    "ratio = 0.8\r\n",
    "train_f = open('/home/aistudio/work/seg/Train/train.txt','w') \r\n",
    "val_f = open('/home/aistudio/work/seg/Train/val.txt' ,'w')\r\n",
    "\r\n",
    "for i ,content in enumerate(path_list):\r\n",
    "    img, mask = content\r\n",
    "    text = img + ' ' + mask + '\\n'\r\n",
    "    if i < len(path_list) * ratio:\r\n",
    "        train_f.write(text)\r\n",
    "    else:\r\n",
    "        val_f.write(text)\r\n",
    "train_f.close()\r\n",
    "val_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.3、导入依赖项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install paddleseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#导入常用的库\r\n",
    "import os\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "from random import shuffle\r\n",
    "import cv2\r\n",
    "import paddle\r\n",
    "from PIL import Image\r\n",
    "import shutil\r\n",
    "import re\r\n",
    "from paddle.vision.transforms import functional as F\r\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二、网络训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.1 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddleseg.transforms as T\n",
    "from paddleseg.datasets import OpticDiscSeg,Dataset\n",
    "\n",
    "train_transforms = [\n",
    "    T.RandomHorizontalFlip(),# 水平翻转\n",
    "    T.RandomVerticalFlip(),# 垂直翻转\n",
    "    T.RandomDistort(0.4),# 随机扭曲\n",
    "    T.RandomBlur(0.3),# 高斯模糊\n",
    "    T.RandomScaleAspect(min_scale=0.5,aspect_ratio=0.5),# 随机缩放\n",
    "    T.Resize(target_size=(512,512)),\n",
    "    T.Normalize()  # 图像标准化\n",
    "\n",
    "]\n",
    "val_transforms = [\n",
    "    T.Resize(target_size=(512,512)),\n",
    "    T.Normalize()\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.2 构建训练集与验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_root = '/home/aistudio/work/seg/Train'\r\n",
    "train_path  = '/home/aistudio/work/seg/Train/train.txt'\r\n",
    "val_path  = '/home/aistudio/work/seg/Train/val.txt'\r\n",
    "# 构建训练集\r\n",
    "train_dataset = Dataset(\r\n",
    "    dataset_root=dataset_root,\r\n",
    "    train_path=train_path,\r\n",
    "    transforms=train_transforms,\r\n",
    "    num_classes=2,\r\n",
    "    mode='train'\r\n",
    "\r\n",
    "                  )\r\n",
    "#验证集\r\n",
    "val_dataset = Dataset(\r\n",
    "    dataset_root=dataset_root,\r\n",
    "    val_path=val_path,\r\n",
    "    transforms=val_transforms,\r\n",
    "    num_classes=2,\r\n",
    "    mode='val'\r\n",
    "\r\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.3 训练配置\n",
    "> 学习率：余弦退火策略（CosineAnnealingDecay）\n",
    "\n",
    "> class paddle.optimizer.lr. CosineAnnealingDecay ( learning_rate, T_max, eta_min=0, last_epoch=- 1, verbose=False )\n",
    "\n",
    "**参数**：\n",
    "* learning_rate (float) - 初始学习率。\n",
    "* T_max (float|int) - 训练的上限轮数，是余弦衰减周期的一半。\n",
    "* eta_min (float|int, 可选) - 学习率的最小值。默认值为0。\n",
    "* last_epoch (int，可选) - 上一轮的轮数，重启训练时设置为上一轮的epoch数。默认值为 -1，则为初始学习率。\n",
    "* verbose (bool，可选) - 如果是 True ，则在每一轮更新时在标准输出 stdout 输出一条信息。默认值为 False 。\n",
    "\n",
    "返回：用于调整学习率的 CosineAnnealingDecay 实例对象。\n",
    "\n",
    "\n",
    "> 优化器：Adam\n",
    "\n",
    "> class paddle.optimizer. Adam ( learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, parameters=None, weight_decay=None, grad_clip=None, name=None, lazy_mode=False )\n",
    "\n",
    "**参数**:\n",
    "\n",
    "*  learning_rate (float|_LRScheduler) - 学习率，用于参数更新的计算。可以是一个浮点型值或者一个_LRScheduler类，默认值为0.001\n",
    "*  beta1 (float|Tensor, 可选) - 一阶矩估计的指数衰减率，是一个float类型或者一个shape为[1]，数据类型为float32的Tensor类型。默认值为0.9\n",
    "*  beta2 (float|Tensor, 可选) - 二阶矩估计的指数衰减率，是一个float类型或者一个shape为[1]，数据类型为float32的Tensor类型。默认值为0.999\n",
    "*  epsilon (float, 可选) - 保持数值稳定性的短浮点类型值，默认值为1e-08\n",
    "*  parameters (list, 可选) - 指定优化器需要优化的参数。在动态图模式下必须提供该参数；在静态图模式下默认值为None，这时所有的参数都将被优化。\n",
    "*  weight_decay (float|WeightDecayRegularizer，可选) - 正则化方法。可以是float类型的L2正则化系数或者正则化策略: cn_api_fluid_regularizer_L1Decay 、 cn_api_fluid_regularizer_L2Decay 。如果一个参数已经在 ParamAttr 中设置了正则化，这里的正则化设置将被忽略； 如果没有在 ParamAttr 中设置正则化，这里的设置才会生效。默认值为None，表示没有正则化。\n",
    "*  grad_clip (GradientClipBase, 可选) – 梯度裁剪的策略，支持三种裁剪策略： paddle.nn.ClipGradByGlobalNorm 、 paddle.nn.ClipGradByNorm 、 paddle.nn.ClipGradByValue 。 默认值为None，此时将不进行梯度裁剪。\n",
    "*  name (str, 可选)- 该参数供开发人员打印调试信息时使用，具体用法请参见 Name ，默认值为None\n",
    "*  lazy_mode （bool, 可选） - 设为True时，仅更新当前具有梯度的元素。官方Adam算法有两个移动平均累加器（moving-average accumulators）。累加器在每一步都会更新。在密集模式和稀疏模式下，两条移动平均线的每个元素都会更新。如果参数非常大，那么更新可能很慢。 lazy mode仅更新当前具有梯度的元素，所以它会更快。但是这种模式与原始的算法有不同的描述，可能会导致不同的结果，默认为False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddleseg.models import UNet\r\n",
    "from paddleseg.models import OCRNet\r\n",
    "from paddleseg.models.losses import CrossEntropyLoss,DiceLoss, MixedLoss\r\n",
    "\r\n",
    "base_lr =0.001\r\n",
    "iters = 16000 \r\n",
    "\r\n",
    "unet_model = UNet(num_classes=2,pretrained='/home/aistudio/output/PLAM_model_3/best_model/model.pdparams')#使用预训练模型unet进行训练\r\n",
    "# unet_model = UNet(num_classes=2)#使用unet进行训练\r\n",
    "\r\n",
    "#自动调整学习率\r\n",
    "lr =paddle.optimizer.lr.CosineAnnealingDecay(base_lr, T_max=(iters // 3), last_epoch=0.5)\r\n",
    "u_optimizer = paddle.optimizer.Adam(lr, parameters=unet_model.parameters())\r\n",
    "\r\n",
    "mixtureLosses = [CrossEntropyLoss(),DiceLoss() ]\r\n",
    "mixtureCoef = [0.7,0.3]\r\n",
    "losses = {}\r\n",
    "losses['types'] = [MixedLoss(mixtureLosses, mixtureCoef)]\r\n",
    "losses['coef'] = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.4 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#进行训练\r\n",
    "from paddleseg.core import train\r\n",
    "train(\r\n",
    "    model = unet_model,\r\n",
    "    train_dataset=train_dataset,\r\n",
    "    val_dataset=val_dataset,\r\n",
    "    optimizer=u_optimizer,\r\n",
    "    save_dir='output/PLAM_model_4',\r\n",
    "    iters=iters,  \r\n",
    "    batch_size=4, \r\n",
    "    save_interval=480,\r\n",
    "    log_iters=10,\r\n",
    "    num_workers=0,\r\n",
    "    losses=losses,\r\n",
    "    use_vdl=True\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.5 模型验证\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddleseg.core import evaluate\r\n",
    "model = UNet(num_classes=2)\r\n",
    "\r\n",
    "#换自己保存的模型文件\r\n",
    "\r\n",
    "model_path = 'output/PLAM_model_4/best_model/model.pdparams'\r\n",
    "\r\n",
    "para_state_dict = paddle.load(model_path)\r\n",
    "model.set_dict(para_state_dict)\r\n",
    "evaluate(model,val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、结果预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.1 生成test.txt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ~\r\n",
    "import random\r\n",
    "import os\r\n",
    "\r\n",
    "test_path = r\"work/seg/test\"\r\n",
    "test_lst=[]\r\n",
    "for test in os.listdir(test_path):              \r\n",
    "    test_lst.append(test)  \r\n",
    "\r\n",
    "with open('work/seg/test.txt', 'w') as f:\r\n",
    "    for line in test_lst:\r\n",
    "        f.write(line)\r\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2 预测分割\n",
    "`PLAM_model_2`、`PLAM_model_3`、`PLAM_model_4`这三个模型皆可达到0.94+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddleseg.core import predict\r\n",
    "import paddleseg.transforms as pt\r\n",
    "transforms = pt.Compose([\r\n",
    "    pt.Resize(target_size=(512, 512)),\r\n",
    "    pt.Normalize()\r\n",
    "])\r\n",
    "\r\n",
    "model = UNet(num_classes=2)\r\n",
    "\r\n",
    "#生成图片列表\r\n",
    "image_list = []\r\n",
    "with open('work/seg/test.txt' ,'r') as f:\r\n",
    "    for line in f.readlines():\r\n",
    "        image_list.append(os.path.join('work/seg/test/',line.split()[0]))\r\n",
    "\r\n",
    "predict(\r\n",
    "        model,\r\n",
    "        #换自己保存的模型文件\r\n",
    "        model_path = 'output/PLAM_model_4/best_model/model.pdparams',\r\n",
    "        transforms=transforms,\r\n",
    "        image_list=image_list,\r\n",
    "        save_dir='results',\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.3 生成结果\n",
    "* 将分割结果二值化，超过127则为255（白色区域），小于 127则为0（黑色区域）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir /home/aistudio/new\r\n",
    "import os \r\n",
    "import cv2\r\n",
    "result_path = '/home/aistudio/results/pseudo_color_prediction'\r\n",
    "dist_path = '/home/aistudio/new'\r\n",
    "for img_name in os.listdir(result_path):\r\n",
    "    img_path = os.path.join(result_path, img_name)\r\n",
    "    img = cv2.imread(img_path)\r\n",
    "    g  = img[:,:,1]\r\n",
    "    ret, result = cv2.threshold(g, 127,255, cv2.THRESH_BINARY_INV)\r\n",
    "    cv2.imwrite(os.path.join(dist_path,img_name), result)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 将分割结果0-255翻转，并填充孔洞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "'''\r\n",
    "图像说明：\r\n",
    "图像为二值化图像，255白色为目标物，0黑色为背景\r\n",
    "要填充白色目标物中的黑色孔洞\r\n",
    "'''\r\n",
    "def FillHole_1(imgPath,SavePath):\r\n",
    "    im_in = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE);\r\n",
    "    th, im_th = cv2.threshold(im_in, 220, 255, cv2.THRESH_BINARY_INV);\r\n",
    "    im_floodfill = im_th.copy()\r\n",
    "    h, w = im_th.shape[:2]\r\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\r\n",
    "    cv2.floodFill(im_floodfill, mask, (0,0), 255);\r\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\r\n",
    "    im_out = im_th | im_floodfill_inv\r\n",
    "    cv2.imwrite(SavePath, im_out)\r\n",
    "\r\n",
    "def FillHole_2(imgPath,SavePath):\r\n",
    "    im_in = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE);\r\n",
    "    # 复制 im_in 图像\r\n",
    "    im_floodfill = im_in.copy()\r\n",
    "    # Mask 用于 floodFill，官方要求长宽+2\r\n",
    "    h, w = im_in.shape[:2]\r\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\r\n",
    "    # floodFill函数中的seedPoint必须是背景\r\n",
    "    isbreak = False\r\n",
    "    for i in range(im_floodfill.shape[0]):\r\n",
    "        for j in range(im_floodfill.shape[1]):\r\n",
    "            if(im_floodfill[i][j]==255):\r\n",
    "                seedPoint=(i,j)\r\n",
    "                isbreak = True\r\n",
    "                break\r\n",
    "        if(isbreak):\r\n",
    "            break\r\n",
    "    # 得到im_floodfill\r\n",
    "    cv2.floodFill(im_floodfill, mask, seedPoint, 0);\r\n",
    "    # 得到im_floodfill的逆im_floodfill_inv\r\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\r\n",
    "    # 把im_in、im_floodfill_inv这两幅图像结合起来得到前景\r\n",
    "    im_out = im_in | im_floodfill\r\n",
    "    cv2.imwrite(SavePath, im_out)\r\n",
    "\r\n",
    "\r\n",
    "result_path = 'new'\r\n",
    "dist_path = 'new'\r\n",
    "\r\n",
    "for img_name in os.listdir(result_path):\r\n",
    "    img_path = os.path.join(result_path, img_name)\r\n",
    "    SavePath = os.path.join(dist_path, img_name)\r\n",
    "\r\n",
    "    FillHole_1(img_path,SavePath)\r\n",
    "    FillHole_2(img_path,SavePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 假如预测中出现多个不连通的区域，只保留最大的区域\n",
    "参考[吖吖查](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/181096)大佬的：[飞桨常规赛：PALM眼底彩照视盘探测与分割 2021 5月第1名方案](https://aistudio.baidu.com/aistudio/projectdetail/1901094?channelType=0&channel=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir /home/aistudio/Disc_Segmentation\r\n",
    "import os \r\n",
    "import cv2\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "def cnt_area(cnt):\r\n",
    "    area = cv2.contourArea(cnt)\r\n",
    "    return area\r\n",
    "\r\n",
    "result_path = '/home/aistudio/new'\r\n",
    "dist_path = '/home/aistudio/Disc_Segmentation'\r\n",
    "for img_name in os.listdir(result_path):\r\n",
    "    img_path = os.path.join(result_path, img_name)\r\n",
    "    img = cv2.imread(img_path)\r\n",
    "    g  = img[:,:,1]\r\n",
    "    ret, threshold = cv2.threshold(g, 127,255, cv2.THRESH_BINARY)\r\n",
    "\r\n",
    "\r\n",
    "    contours, hierarch = cv2.findContours(threshold, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\r\n",
    "    contours.sort(key=cnt_area, reverse=True)\r\n",
    "    if len(contours) > 1:\r\n",
    "        for i in range(1,len(contours)):\r\n",
    "            cv2.drawContours(threshold, [contours[i]], 0, 0, -1)\r\n",
    "    _,result = cv2.threshold(threshold, 127, 255, cv2.THRESH_BINARY_INV)\r\n",
    "    cv2.imwrite(os.path.join(dist_path, img_name), result)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 结果打包\n",
    "将结果打包，下载皆可提交：[提交](https://aistudio.baidu.com/aistudio/competition/detail/87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 压缩当前路径所有文件，输出zip文件\r\n",
    "path='Disc_Segmentation'\r\n",
    "\r\n",
    "import zipfile,os\r\n",
    "zipName = 'Disc_Segmentation.zip' #压缩后文件的位置及名称\r\n",
    "f = zipfile.ZipFile( zipName, 'w', zipfile.ZIP_DEFLATED )\r\n",
    "for dirpath, dirnames, filenames in os.walk(path):\r\n",
    "    for filename in filenames:\r\n",
    "        print(filename)\r\n",
    "        f.write(os.path.join(dirpath,filename))\r\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 项目总结及建议\n",
    "* 【孔洞填充】因为视盘相对于图片相对较小，在分数已经到达0.93以上的话，孔洞填充只能提升0.00002左右，分数越高效果越小\n",
    "* 【数据增强】图片大小512x512，水平翻转，对比度随机改变等数据增强\n",
    "* 【异常结果处理】将分割结果中出现的不连通的区域去除。与第一条相似，分数越高效果越小\n",
    "\n",
    "\n",
    "眼底彩照视盘探测与分割相关论文：\n",
    "\n",
    "1. [Detection of Pathological Myopia and Optic Disc Segmentation with Deep Convolutional Neural Networks ](https://ieeexplore.ieee.org/abstract/document/8929252)\n",
    "1. [Patch-Based Output Space Adversarial Learning for Joint Optic Disc and Cup Segmentation ](https://ieeexplore.ieee.org/abstract/document/8643416/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨使用体验+给其他选手学习飞桨的建议\n",
    "\n",
    "1. 飞浆有许多免费的课程，多加入课程，多学习其中各种比赛案例\n",
    "1. 建议各选手多看大佬们写的项目，多借鉴其他人的观点以完善自己的项目，初学者可以使用飞浆的各种套件进行训练\n",
    "1. Visual DL 能够更直观更快速地看见调参对比情况，希望Visual DL快点回归\n",
    "\n",
    "\n",
    "PaddleSeg真好用，更全面的PaddleSeg介绍可参考[Github链接](https://github.com/PaddlePaddle/PaddleSeg)。欢迎star!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
